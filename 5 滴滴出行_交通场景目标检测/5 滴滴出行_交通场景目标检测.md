# 案例5：滴滴出行-交通场景目标检测

相关知识点：目标检测、开源框架的配置和使用（mmdetection, mmcv） 

## 1 任务目标

### **1**.1 任务和数据简介

   本次案例将使用深度学习技术来完成城市交通场景下的目标检测任务，案例所使用的数据集由滴滴出行提供，基于D^2^-City大规模行车记录视频数据集^[1]^，经过视频抽帧等预处理步骤得到。数据集共包含12,000张图像，每张图像的大小为1080×1920或720×1280，已划分为训练集(10,000张)、验证集(1,000张)、测试集(1,000张)，其中训练集和验证集提供了检测标签，测试集仅提供图像，用于提交后测试模型效果。本数据集共包含12个待检测的物体类别，包括小汽车、公交车、自行车、行人等，具体定义及示例如图1所示。本任务的目标是在给定的交通场景图像中，尽可能完整、准确地检测出所有要求的物体，检测结果示例如图2所示。关于数据的更多细节可参考D^2^-City文献^[1]^.

   为了方便使用，数据集的标注信息已被预处理成MS-COCO格式，MS-COCO是通用物体检测领域最常用的数据集，如需深入理解数据集格式，请自行学习：MS-COCO数据集官网^[2]^、MS-COCO数据集文献^[3]^、MS-COCO标注格式^[4]^. 模型的评估指标也使用MS-COCO常用指标mAP(mean average precision)，请自行学习其定义及计算方式(无需自己实现)：mAP定义^[5]^，mAP计算方式^[6][7]^。

### 1.2 参考程序及使用说明

   本次案例提供了完整、可供运行的参考程序，选取了带FPN^[8]^结构的Faster R-CNN^[9]^模型，基于MMDetection物体检测框架^[10]^实现，各程序简介如下：

- `faster_rcnn_r50_fpn_1x_didi.py`为模型配置文件，安装MMDetection后置于`mmdetection/configs/faster_rcnn`路径下；

- `didi_detection.py`为数据集配置文件，置于`mmdetection/configs/_base_/datasets`路径下，并将data_root变量修改为数据集所在路径；

- `test.json`为测试数据集文件信息，置于`mmdetection/[数据集所在路径]/dataset_release`路径下，在测试集上做推理时会用到；

- `didi_demo.ipynb`用于可视化模型的检测结果。

### 1.3 参考程序的使用步骤及说明

- 自行安装MMDetection最新版(v3.2.0)及其全部依赖库，包括PyTorch等(MMDetection GitHub: ^[10]^，安装指南: ^[11]^)；
- 学习必要的使用说明：MMDetection文档^[12]^ (请务必仔细阅读Getting Started章节)；

## 2 通过云平台训练基础代码

​	在本次实验中，并没有给出全部的代码，需要自己从 github 上 clone [MMdetection 项目](https://github.com/open-mmlab/mmdetection)，并自己学习 [MMdetection 文档](https://mmdetection.readthedocs.io/zh-cn/latest/get_started.html)，来完成整个项目。

### 2.1 环境配置

​	创建项目，点击右上角设置按钮配置环境。选择“挂载Work目录”，“T4 GPU”，“GPU Pytorch1.6 Tensorflow 2.3.0 Python 3.8.5”完成基础环境配置。本次训练时长较长，占用云平台空间较大，需要挂载 work 文件夹，不然可能会提示 protect文件夹 空间不足。

![image-20240301221212761](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240301221212761.png)

运行程序，上传本地文件，到project文件夹。

### 2.2 项目配置

本环节需要配置 MMdetection 的环境，根据文档内容，下载安装一些必备库。

1. 更新pip

   之后安装的库，需要高版本的pip，所以需要先更新pip。在Jupyter的代码框中，运行以下命令。

   ```bat
   !pip install --upgrade pip
   ```

2. 将 `test.json` 置于 `/home/mw/input/datasets1367/dataset/dataset_release `文件夹中

   在Jupyter的代码框中，运行以下命令，完成文件的拷贝。

   ```bat
   %cp /home/mw/project/test.json /home/mw/input/datasets1367/dataset/dataset_release 
   ```

3. 用 [MIM](https://github.com/open-mmlab/mim) 安装 [MMEngine](https://github.com/open-mmlab/mmengine) 和 [MMCV](https://github.com/open-mmlab/mmcv)

   ```bat
   !pip3 install openmim
   !mim install mmengine
   !mim install "mmcv>=2.0.0,<2.1.0"
   ```

   安装完成后，会显示`Successfully installed mmcv-2.1.0 mmengine-0.10.3 ...` 等内容。

4. 使用源码安装 MMDetection

   ```bat
   !git clone https://github.com/open-mmlab/mmdetection.git
   %cd mmdetection
   !pip install -e .
   ```

   安装完成后，project文件夹中，会出现mmdetection文件夹。

5. 文件配置

   将 `faster_rcnn_r50_fpn_1x_didi.py` 复制到 `mmdetection/configs/faster_rcnn`路径下。

   将`didi_detection.py` 复制到`mmdetection/configs/_base_/datasets`路径下，并将data_root变量修改为数据集所在路径。

   ```bash
   data_root = '/home/mw/input/datasets1367/dataset/dataset_release/'
   ```

### 2.3 项目训练

1. 在线训练

   在Jupyter的代码框中，运行以下命令，开始项目的训练。

   ```bat
   %cd /home/mw/project/mmdetection
   !python ./tools/train.py ./configs/faster_rcnn/faster_rcnn_r50_fpn_1x_didi.py --work-dir /home/mw/work/work_dir
   ```

   当看到程序运行显示以下内容，表示程序已经成功进行训练。

   ```cmd
   02/29 06:00:41 - mmengine - INFO - Epoch(train)  [1][  50/5000]  lr: 1.9820e-03  eta: 9:34:04  time: 0.5746  data_time: 0.0061  memory: 3606  loss: 1.4120  loss_rpn_cls: 0.4417  loss_rpn_bbox: 0.0850  loss_cls: 0.8184  acc: 92.2852  loss_bbox: 0.0669
   02/29 06:01:08 - mmengine - INFO - Epoch(train)  [1][ 100/5000]  lr: 3.9840e-03  eta: 9:17:54  time: 0.5431  data_time: 0.0047  memory: 3606  loss: 0.7339  loss_rpn_cls: 0.1702  loss_rpn_bbox: 0.0733  loss_cls: 0.3048  acc: 95.0195  loss_bbox: 0.1856
   ...
   ```

2. 离线训练

   > 本程序训练需要12个epoch，训练时长需要8~10个小时，在线训练需要保持一直联网，不然就会断掉，所以建议放到离线环境上运行。

   当以上步骤全部跑通后，测试项目是否可以点击 “运行全部” 就可以执行所有代码，完成项目训练。如果可以，则可以放在离线任务中训练。

   在长达10个小时的离线训练后，终于完成了离线训练，可以在云平台的离线训练日志中，看到训练进度以及资源占用。

   ![image-20240302130335293](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240302130335293.png)

   ![image-20240302130411320](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240302130411320.png)

3. 训练结果分析

   训练结束后在work_dirs文件夹中存储训练项目日志以及保存的模型。

   项目运行结束后，最后一轮训练结果如下。

   ![image-20240301230910260](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240301230910260.png)

   模型采用了**平均精度 (AP)**、**平均召回率 (AR)** 、**IoU** 、**maxDets** 和 **Area** 四个维度对模型进行评估，下面介绍以上信息具体内容。

   - **IoU(Intersection over Union)**

     **IoU** 是一个用于评估目标检测模型性能的常见指标。它衡量了模型预测的边界框（bounding box）与真实边界框之间的重叠程度。

   - **目标对象大小 Area**

     MMDetection 将 Area 分为三类：small, medium, 和 large，代表了小、中、大不同尺寸的目标。

   - **maxDets (Maximum Detections)**

     maxDets用于限制每张图像或每个类别的最大检测数量。限制每个图像或每个类别的最大检测数，以便更全面地评估模型的准确性。

   - **平均精度 AP (Average Precision)**

     平均精度是在不同IoU阈值下计算出的精度的平均值，是指模型预测为正类别的样本中有多少是真正的正例。

     - 在所有的目标尺寸上，IoU 从 0.50 到 0.95 的平均精度 (AP) 为 0.290；IoU 为 0.50 时平均精度(AP)最高，达到0.492；IoU 为 0.75 时平均精度(AP)为0.293。

       可以看出，AP 的计算中，更高的 IoU 阈值通常对模型提出更严格的要求。

     - 当 IoU 在0.5到0.95之间，小目标的平均精度(AP) 最低，只有0.120；中等目标的平均精度(AP) 为0.321；大目标的平均精度(AP) 最高，为0.456。

       可以看出，对识别尺寸越大的目标，模型的平均精度(AP) 就越高。

   - **平均召回率 AR (Average Recall)**

     平均召回率是在不同IoU阈值下计算出的召回率的平均值，是指所有真正的正例中，模型成功预测为正类别的比例。

     - 在所有的目标尺寸上，当IoU 在 0.50 到 0.95 之间，在maxDets 为100、300、1000的平均召回率 (AR) 都为 0.449。

       可以看出maxDets 对AR没有影响。

     - 当 IoU 在0.5到0.95之间，小目标的平均召回率(AR) 最低，只有0.252；中等目标的平均召回率(AR)为0.482；大目标的平均召回率(AR)最高，为0.642。

       可以看出，对识别尺寸越大的目标，模型的平均召回率 (AR) 就越高。

## 3 在本地训练基础代码

​	因为云平台环境配置总容易出问题，之后我便换到了本地进行训练以及进一步的测试。

### 3.1 环境配置

​	环境配置和云平台类似，可以通过查看 [MMDetection文档](https://mmdetection.readthedocs.io/zh-cn/latest/get_started.html) 来完成配置。

1. 创建并激活一个 conda 环境

   ```bash
   conda create --name openmmlab python=3.8 -y
   conda activate openmmlab
   ```

2. 基于 [Pytorch官方平台](https://pytorch.org/get-started/locally/) 安装Pytorch

   ```bash
   conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia
   ```

3. 使用 [MIM](https://github.com/open-mmlab/mim) 安装 [MMEngine](https://github.com/open-mmlab/mmengine) 和 [MMCV](https://github.com/open-mmlab/mmcv)

   ```bash
   pip install -U openmim
   mim install mmengine
   mim install "mmcv>=2.0.0"
   ```

4. 安装 MMDetection

   ```bash
   git clone https://github.com/open-mmlab/mmdetection.git
   cd mmdetection
   pip install -v -e .
   ```

   安装完成后，会生成一个mmdetection文件夹。

5. 文件配置

   - 将`test.json`置于`mmdetection/[数据集所在路径]/dataset_release`路径下。
   - 将 `faster_rcnn_r50_fpn_1x_didi.py` 复制到 `mmdetection/configs/faster_rcnn`路径下。

   - 将`didi_detection.py` 复制到`mmdetection/configs/_base_/datasets`路径下，并将data_root变量修改为数据集所在路径。

     ```bash
     data_root = 'xxxx/dataset_release/'
     ```

### 3.2 项目训练

1. 训练项目

   在mmdetection文件夹下，通过命令行窗口执行以下命令。

   ```cmd
   python tools/train.py configs/faster_rcnn/faster_rcnn_r50_fpn_1x_didi.py
   ```

   显示以下内容，说明成功开始训练。

   ```cmd
   02/29 06:00:41 - mmengine - INFO - Epoch(train)  [1][  50/5000]  lr: 1.9820e-03  eta: 9:34:04  time: 0.5746  data_time: 0.0061  memory: 3606  loss: 1.4120  loss_rpn_cls: 0.4417  loss_rpn_bbox: 0.0850  loss_cls: 0.8184  acc: 92.2852  loss_bbox: 0.0669
   02/29 06:01:08 - mmengine - INFO - Epoch(train)  [1][ 100/5000]  lr: 3.9840e-03  eta: 9:17:54  time: 0.5431  data_time: 0.0047  memory: 3606  loss: 0.7339  loss_rpn_cls: 0.1702  loss_rpn_bbox: 0.0733  loss_cls: 0.3048  acc: 95.0195  loss_bbox: 0.1856
   ...
   ```

   > 注意，训练时长还是比较长的，我是4060的显卡，训练时间大约有6个小时

2. 训练结果分析

   在命令行窗口训练，输出的结果只显示在窗口中，但是在文件夹中存有了log日志文件。

   在`.\mmdetection\work_dirs\faster_rcnn_r50_fpn_1x_didi\20240229_232911`文件夹下，有以下文件：

   ```cmd
   20240229_232911
   ├── 20240229_232911.log			# 训练日志文件
   ├── vis_data
   │   ├── 20240229_232911.json	# 与scalars.json相同
   │   ├── config.py				# 训练配置信息：包括训练的模型、数据集地址等信息
   │   ├── scalars.json			# 训练数据信息：包括每轮训练的loss、mAP等信息
   ```

   可以从 `20240229_232911.log` 中的最后，看到第12轮训练的结果。

   ```cmd
   2024/03/01 05:26:41 - mmengine - INFO - bbox_mAP_copypaste: 0.283 0.476 0.289 0.126 0.303 0.447
   2024/03/01 05:26:41 - mmengine - INFO - Epoch(val) [12][500/500]    coco/bbox_mAP: 0.2830  coco/bbox_mAP_50: 0.4760  coco/bbox_mAP_75: 0.2890  coco/bbox_mAP_s: 0.1260  coco/bbox_mAP_m: 0.3030  coco/bbox_mAP_l: 0.4470  data_time: 0.0014  time: 0.1407
   ```

   其中，通过`tools/analysis_tools/analyze_logs.py` 可利用指定的训练 log 文件绘制 loss 曲线图， 第一次运行前请先运行 `pip install seaborn` 安装必要依赖。

   ```cmd
   python tools/analysis_tools/analyze_logs.py plot_curve work_dirs/faster_rcnn_r50_fpn_1x_didi/20240229_232911/vis_data/20240229_232911.json --keys loss_cls loss_bbox  --legend loss_cls loss_bbox --out work_dirs/log.png
   ```

   ![log2](https://raw.githubusercontent.com/ZzDarker/figure/main/img/log2.png)

### 3.3 项目测试

1. 在测试集测试性能

   利用 MMDetection 的 `test.py` ，对数据集上进行测试，对交通图像进行标注。

   ```cmd
   python ./tools/test.py ./configs/faster_rcnn/faster_rcnn_r50_fpn_1x_didi.py ./work_dirs/faster_rcnn_r50_fpn_1x_didi/epoch_12.pth  --out ./work_dirs/faster_rcnn_r50_fpn_1x_didi/result.pkl --show-dir ./work_dir/faster_rcnn_r50_fpn_1x_didi/test_show/
   ```

   输出结果如下：

   ![image-20240302165333266](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240302165333266.png)

   生成了一个 `result.pkl` 文件，并得到了以下测试图片：

   ![11000](https://raw.githubusercontent.com/ZzDarker/figure/main/img/11000.jpg)

   ![image-20240302160145463](https://raw.githubusercontent.com/ZzDarker/figure/main/img/image-20240302160145463.png)

2. 结果分析

   利用 `analyze_results.py` 进行结果分析。

   ```cmd
   python ./tools/analysis_tools/analyze_results.py ./work_dirs/faster_rcnn_r50_fpn_1x_didi/20240229_232911/vis_data/config.py ./work_dirs/faster_rcnn_r50_fpn_1x_didi/result.pkl ./work_dirs/faster_rcnn_r50_fpn_1x_didi/analyze_results
   ```

3. 绘制混淆矩阵

   ```cmd
   python ./tools/analysis_tools/confusion_matrix.py ./work_dirs/faster_rcnn_r50_fpn_1x_didi/20240229_232911/vis_data/config.py ./work_dirs/faster_rcnn_r50_fpn_1x_didi/result.pkl ./work_dirs/faster_rcnn_r50_fpn_1x_didi/confusion_matrix --show
   ```

4. 测试mAP

   ```cmd
   python ./tools/analysis_tools/eval_metric.py ./work_dirs/faster_rcnn_r50_fpn_1x_didi/20240229_232911/vis_data/config.py ./work_dirs/faster_rcnn_r50_fpn_1x_didi/result.pkl
   ```

   

